{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 8 : Déployer un modèle dans le cloud\n",
    "## Partie 2 : Extraction des features dans le cloud \n",
    "\n",
    "Ce notebook est déjà lancé par la commande pyspark qui utilise le notebook comme driver, donc le SparkContext est déjà initialisé comme le montre la commande ci dessous \n",
    "Dans la première partie on a sauvé un échantillon de nos données sur le S3 d'Amazon, dans cette partie, on va juste pouvoir extraire les features en utilisant SparkDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-11-125.us-east-2.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5-amzn-0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hadoop/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hadoop/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hadoop/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hadoop/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hadoop/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml.image import ImageSchema\n",
    "import boto3\n",
    "from sparkdl import DeepImageFeaturizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par récupérer la bucket S3, notons que les credentials et la config se trouve dans le répertoire ~/.aws/credentials et ~/.aws/config comme l'expliquait la documentation Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket_name = 'oc-p8-salah'\n",
    "region = 'us-east-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit une dataframe spark, avec comme colonne l'image, et bien entendu son label sur l'échantillon d'images qu'on a récupérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/126_100.jpg count = 0\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/158_100.jpg count = 1\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/170_100.jpg count = 2\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/31_100.jpg count = 3\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/58_100.jpg count = 4\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/r_132_100.jpg count = 5\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/r_146_100.jpg count = 6\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/r_172_100.jpg count = 7\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/r_231_100.jpg count = 8\n",
      "Done for img s3a://oc-p8-salah/Cherry_Wax_Yellow/r_247_100.jpg count = 9\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/263_100.jpg count = 10\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/318_100.jpg count = 11\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/88_100.jpg count = 12\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/r_151_100.jpg count = 13\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/r_153_100.jpg count = 14\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/r_161_100.jpg count = 15\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/r_177_100.jpg count = 16\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/r_196_100.jpg count = 17\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/r_223_100.jpg count = 18\n",
      "Done for img s3a://oc-p8-salah/Kohlrabi/r_246_100.jpg count = 19\n",
      "Done for img s3a://oc-p8-salah/Mulberry/109_100.jpg count = 20\n",
      "Done for img s3a://oc-p8-salah/Mulberry/310_100.jpg count = 21\n",
      "Done for img s3a://oc-p8-salah/Mulberry/57_100.jpg count = 22\n",
      "Done for img s3a://oc-p8-salah/Mulberry/98_100.jpg count = 23\n",
      "Done for img s3a://oc-p8-salah/Mulberry/9_100.jpg count = 24\n",
      "Done for img s3a://oc-p8-salah/Mulberry/r_107_100.jpg count = 25\n",
      "Done for img s3a://oc-p8-salah/Mulberry/r_178_100.jpg count = 26\n",
      "Done for img s3a://oc-p8-salah/Mulberry/r_317_100.jpg count = 27\n",
      "Done for img s3a://oc-p8-salah/Mulberry/r_324_100.jpg count = 28\n",
      "Done for img s3a://oc-p8-salah/Mulberry/r_61_100.jpg count = 29\n",
      "Done for img s3a://oc-p8-salah/Peach/314_100.jpg count = 30\n",
      "Done for img s3a://oc-p8-salah/Peach/320_100.jpg count = 31\n",
      "Done for img s3a://oc-p8-salah/Peach/r2_274_100.jpg count = 32\n",
      "Done for img s3a://oc-p8-salah/Peach/r2_321_100.jpg count = 33\n",
      "Done for img s3a://oc-p8-salah/Peach/r_107_100.jpg count = 34\n",
      "Done for img s3a://oc-p8-salah/Peach/r_177_100.jpg count = 35\n",
      "Done for img s3a://oc-p8-salah/Peach/r_219_100.jpg count = 36\n",
      "Done for img s3a://oc-p8-salah/Peach/r_261_100.jpg count = 37\n",
      "Done for img s3a://oc-p8-salah/Peach/r_289_100.jpg count = 38\n",
      "Done for img s3a://oc-p8-salah/Peach/r_96_100.jpg count = 39\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/181_100.jpg count = 40\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/190_100.jpg count = 41\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/31_100.jpg count = 42\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/r_182_100.jpg count = 43\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/r_185_100.jpg count = 44\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/r_226_100.jpg count = 45\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/r_248_100.jpg count = 46\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/r_308_100.jpg count = 47\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/r_309_100.jpg count = 48\n",
      "Done for img s3a://oc-p8-salah/Peach_Flat/r_315_100.jpg count = 49\n",
      "Done for img s3a://oc-p8-salah/Pear/113_100.jpg count = 50\n",
      "Done for img s3a://oc-p8-salah/Pear/123_100.jpg count = 51\n",
      "Done for img s3a://oc-p8-salah/Pear/145_100.jpg count = 52\n",
      "Done for img s3a://oc-p8-salah/Pear/209_100.jpg count = 53\n",
      "Done for img s3a://oc-p8-salah/Pear/r2_195_100.jpg count = 54\n",
      "Done for img s3a://oc-p8-salah/Pear/r_105_100.jpg count = 55\n",
      "Done for img s3a://oc-p8-salah/Pear/r_169_100.jpg count = 56\n",
      "Done for img s3a://oc-p8-salah/Pear/r_303_100.jpg count = 57\n",
      "Done for img s3a://oc-p8-salah/Pear/r_309_100.jpg count = 58\n",
      "Done for img s3a://oc-p8-salah/Pear/r_315_100.jpg count = 59\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/110_100.jpg count = 60\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/123_100.jpg count = 61\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/56_100.jpg count = 62\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/r_107_100.jpg count = 63\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/r_111_100.jpg count = 64\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/r_124_100.jpg count = 65\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/r_152_100.jpg count = 66\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/r_156_100.jpg count = 67\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/r_161_100.jpg count = 68\n",
      "Done for img s3a://oc-p8-salah/Pear_Kaiser/r_91_100.jpg count = 69\n",
      "Done for img s3a://oc-p8-salah/Plum/112_100.jpg count = 70\n",
      "Done for img s3a://oc-p8-salah/Plum/252_100.jpg count = 71\n",
      "Done for img s3a://oc-p8-salah/Plum/39_100.jpg count = 72\n",
      "Done for img s3a://oc-p8-salah/Plum/r2_184_100.jpg count = 73\n",
      "Done for img s3a://oc-p8-salah/Plum/r2_272_100.jpg count = 74\n",
      "Done for img s3a://oc-p8-salah/Plum/r3_86_100.jpg count = 75\n",
      "Done for img s3a://oc-p8-salah/Plum/r_131_100.jpg count = 76\n",
      "Done for img s3a://oc-p8-salah/Plum/r_218_100.jpg count = 77\n",
      "Done for img s3a://oc-p8-salah/Plum/r_253_100.jpg count = 78\n",
      "Done for img s3a://oc-p8-salah/Plum/r_65_100.jpg count = 79\n",
      "Done for img s3a://oc-p8-salah/Salak/103_100.jpg count = 80\n",
      "Done for img s3a://oc-p8-salah/Salak/179_100.jpg count = 81\n",
      "Done for img s3a://oc-p8-salah/Salak/89_100.jpg count = 82\n",
      "Done for img s3a://oc-p8-salah/Salak/r_144_100.jpg count = 83\n",
      "Done for img s3a://oc-p8-salah/Salak/r_251_100.jpg count = 84\n",
      "Done for img s3a://oc-p8-salah/Salak/r_45_100.jpg count = 85\n",
      "Done for img s3a://oc-p8-salah/Salak/r_46_100.jpg count = 86\n",
      "Done for img s3a://oc-p8-salah/Salak/r_69_100.jpg count = 87\n",
      "Done for img s3a://oc-p8-salah/Salak/r_85_100.jpg count = 88\n",
      "Done for img s3a://oc-p8-salah/Salak/r_94_100.jpg count = 89\n",
      "+--------------------+-----------------+\n",
      "|               image|            label|\n",
      "+--------------------+-----------------+\n",
      "|[s3a://oc-p8-sala...|Cherry_Wax_Yellow|\n",
      "|[s3a://oc-p8-sala...|Cherry_Wax_Yellow|\n",
      "|[s3a://oc-p8-sala...|Cherry_Wax_Yellow|\n",
      "+--------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_bucket = s3_resource.Bucket(bucket_name)\n",
    "path_prefix = 's3a://' + bucket_name + '/'\n",
    "main_df = None\n",
    "i = 0\n",
    "for bucket_object in s3_bucket.objects.all():\n",
    "    if not bucket_object.key.endswith('.jpg'):\n",
    "        continue\n",
    "    label = bucket_object.key.split('/')[0]\n",
    "    img_path = path_prefix + bucket_object.key\n",
    "    img_df = ImageSchema.readImages(img_path).withColumn('label', lit(label))\n",
    "    if main_df is None:\n",
    "        main_df = img_df\n",
    "    else:\n",
    "        main_df = main_df.unionAll(img_df)\n",
    "    print('Done for img {} count = {}'.format(img_path,i))\n",
    "    i+=1\n",
    "\n",
    "main_df.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre dataframe étant prête, il ne reste plus qu'à en extraire les features, pour celà on va utiliser du transfer learning et utiliser le ResNet50 pour extraires les features des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = DeepImageFeaturizer(\n",
    "    inputCol='image',\n",
    "    outputCol='feature',\n",
    "    modelName='ResNet50'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons quelques échantillons de la dataframe, et aussi son schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+\n",
      "|               image|            label|             feature|\n",
      "+--------------------+-----------------+--------------------+\n",
      "|[s3a://oc-p8-sala...|Cherry_Wax_Yellow|[0.15766188502311...|\n",
      "|[s3a://oc-p8-sala...|Cherry_Wax_Yellow|[0.35756713151931...|\n",
      "|[s3a://oc-p8-sala...|Cherry_Wax_Yellow|[0.52175581455230...|\n",
      "+--------------------+-----------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df = featurizer.transform(main_df)\n",
    "features_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = false)\n",
      " |    |-- width: integer (nullable = false)\n",
      " |    |-- nChannels: integer (nullable = false)\n",
      " |    |-- mode: integer (nullable = false)\n",
      " |    |-- data: binary (nullable = false)\n",
      " |-- label: string (nullable = false)\n",
      " |-- feature: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement reste plus qu'à sauver cette dataframe, on préfère utiliser le format parquet bien utile pour sauver à la fois les images autant qu'objets, ainsi que les features autant que vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.write.format('parquet').mode('overwrite').save('s3a://' + bucket_name + '/processed.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
